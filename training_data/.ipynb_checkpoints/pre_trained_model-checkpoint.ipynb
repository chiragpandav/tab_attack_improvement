{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "173391b8-2064-469b-aebc-594fdc84509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import to_numeric\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.eval_metrics import get_acc_and_bac\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datasets.base_dataset import BaseDataset\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, recall_score,precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05527257-e893-4f97-abce-ad866f9f08a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinReLU(nn.Module):\n",
    "    \"\"\"\n",
    "    A linear layer followed by a ReLU activation layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(LinReLU, self).__init__()\n",
    "\n",
    "        linear = nn.Linear(in_size, out_size)\n",
    "        ReLU = nn.ReLU()\n",
    "        # self.Dropout = nn.Dropout(0.25)\n",
    "        self.layers = nn.Sequential(linear, ReLU)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.layers[0].reset_parameters()\n",
    "        return self\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FullyConnected(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple fully connected neural network with ReLU activations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, layout):\n",
    "\n",
    "        super(FullyConnected, self).__init__()\n",
    "        layers = [nn.Flatten()]  # does not play any role, but makes the code neater\n",
    "        prev_fc_size = input_size\n",
    "        for i, fc_size in enumerate(layout):\n",
    "            if i + 1 < len(layout):\n",
    "                layers += [LinReLU(prev_fc_size, fc_size)]\n",
    "            else:\n",
    "                layers += [nn.Linear(prev_fc_size, fc_size)]\n",
    "            prev_fc_size = fc_size\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68d892f-7c44-45b9-a41b-66a1f5758a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3c402-59de-4923-bafa-50a00080cb60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091adda2-b253-4f39-a1c1-e1b2a1ccd54d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1496b515-22bb-4b55-9a7e-c2a14ad4f50b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abbba72f-18a9-4da4-a94e-ac50cfff21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../clients_data/processed_data/data_pre_trained_model.pkl', 'rb') as f:\n",
    "    train_data_all_client  = pickle.load(f)\n",
    "\n",
    "with open('../clients_data/processed_data/client_adult.pkl', 'rb') as f:\n",
    "    test_data  = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9ea49fa-0708-482f-9019-c0e050956973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data points_ 2624\n",
      "all data points_ 10016\n"
     ]
    }
   ],
   "source": [
    "client_data_dir = \"clients_data/processed_data/\"\n",
    "layout = [100, 100, 2]\n",
    "batch_size = 32\n",
    "num_epochs = 15\n",
    "input_dim = 105\n",
    "lr = 0.01\n",
    "\n",
    "print(f\"all data points_\", len(train_data_all_client)*32)   \n",
    "print(f\"all data points_\", len(test_data)*32)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b95ec-5539-4a21-9f98-6adbf8d966e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3104d1ba-a1c3-4226-bcde-5dd13ab809a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Training Loss: 0.4762, Training Accuracy: 0.7771\n",
      "Validation Loss: 0.5712, Validation Accuracy: 0.7222\n",
      "Epoch [2/15], Training Loss: 0.4052, Training Accuracy: 0.8077\n",
      "Validation Loss: 0.5605, Validation Accuracy: 0.7617\n",
      "Epoch [3/15], Training Loss: 0.3884, Training Accuracy: 0.8203\n",
      "Validation Loss: 0.5077, Validation Accuracy: 0.7658\n",
      "Epoch [4/15], Training Loss: 0.3750, Training Accuracy: 0.8169\n",
      "Validation Loss: 0.4210, Validation Accuracy: 0.7690\n",
      "Epoch [5/15], Training Loss: 0.3612, Training Accuracy: 0.8318\n",
      "Validation Loss: 0.5020, Validation Accuracy: 0.7493\n",
      "Epoch [6/15], Training Loss: 0.3480, Training Accuracy: 0.8322\n",
      "Validation Loss: 0.4332, Validation Accuracy: 0.7883\n",
      "Epoch [7/15], Training Loss: 0.3401, Training Accuracy: 0.8314\n",
      "Validation Loss: 0.4930, Validation Accuracy: 0.7358\n",
      "Epoch [8/15], Training Loss: 0.3296, Training Accuracy: 0.8437\n",
      "Validation Loss: 0.3981, Validation Accuracy: 0.8021\n",
      "Epoch [9/15], Training Loss: 0.3202, Training Accuracy: 0.8410\n",
      "Validation Loss: 0.6162, Validation Accuracy: 0.7854\n",
      "Epoch [10/15], Training Loss: 0.3203, Training Accuracy: 0.8452\n",
      "Validation Loss: 0.5273, Validation Accuracy: 0.7983\n",
      "Epoch [11/15], Training Loss: 0.2877, Training Accuracy: 0.8540\n",
      "Validation Loss: 0.5396, Validation Accuracy: 0.7927\n",
      "Epoch [12/15], Training Loss: 0.2842, Training Accuracy: 0.8620\n",
      "Validation Loss: 0.6547, Validation Accuracy: 0.7381\n",
      "Epoch [13/15], Training Loss: 0.2782, Training Accuracy: 0.8647\n",
      "Validation Loss: 0.6298, Validation Accuracy: 0.7577\n",
      "Epoch [14/15], Training Loss: 0.2741, Training Accuracy: 0.8582\n",
      "Validation Loss: 0.7123, Validation Accuracy: 0.7491\n",
      "Epoch [15/15], Training Loss: 0.2621, Training Accuracy: 0.8620\n",
      "Validation Loss: 0.8889, Validation Accuracy: 0.7364\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = FullyConnected(input_dim, layout)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Initialize gradients list\n",
    "gradients = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    model.train()\n",
    "    for inputs, labels in train_data_all_client:\n",
    "        # Ensure inputs and labels are on the same device as the model\n",
    "        # inputs, labels = inputs.to(model.parameters().__next__().device), labels.to(model.parameters().__next__().device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Store gradients\n",
    "        batch_gradients = [param.grad.clone() for param in model.parameters() if param.grad is not None]\n",
    "        gradients.append(batch_gradients)\n",
    "\n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted_classes = torch.max(outputs, dim=1)\n",
    "        correct += (predicted_classes == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_data_all_client)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Training Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_running_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        for inputs, labels in test_data:\n",
    "            # Ensure inputs and labels are on the same device as the model\n",
    "            # inputs, labels = inputs.to(model.parameters().__next__().device), labels.to(model.parameters().__next__().device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            val_running_loss += val_loss.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted_classes = torch.max(outputs, dim=1)\n",
    "            val_correct += (predicted_classes == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "        val_epoch_loss = val_running_loss / len(test_data)\n",
    "        val_accuracy = val_correct / val_total\n",
    "        print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fddb35e-1ac6-426a-89e4-7b6ed145b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = FullyConnected(input_dim, layout)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# gradients = []\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     running_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "\n",
    "#     model.train()\n",
    "#     for inputs, labels in train_data_all_client:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "\n",
    "#         batch_gradients = [param.grad.clone() for param in model.parameters() if param.grad is not None]\n",
    "#         gradients.append(batch_gradients)\n",
    "\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#         _, predicted_classes = torch.max(outputs, dim=1)\n",
    "#         correct += (predicted_classes == labels).sum().item()\n",
    "#         total += labels.size(0)\n",
    "\n",
    "#     epoch_loss = running_loss / len(train_data_all_client)\n",
    "#     accuracy = correct / total\n",
    "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Training Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         val_running_loss = 0.0\n",
    "#         val_correct = 0\n",
    "#         val_total = 0\n",
    "\n",
    "#         all_preds = []\n",
    "#         all_labels = []\n",
    "\n",
    "#         for inputs, labels in test_data:\n",
    "#             outputs = model(inputs)\n",
    "#             val_loss = criterion(outputs, labels)\n",
    "#             val_running_loss += val_loss.item()\n",
    "\n",
    "#             _, predicted_classes = torch.max(outputs, dim=1)\n",
    "#             val_correct += (predicted_classes == labels).sum().item()\n",
    "#             val_total += labels.size(0)\n",
    "\n",
    "#             all_preds.extend(predicted_classes.cpu().numpy())  \n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "#         val_epoch_loss = val_running_loss / len(test_data)\n",
    "#         val_accuracy = val_correct / val_total\n",
    "#         val_f1 = f1_score(all_labels, all_preds, average='micro')\n",
    "#         val_recall = recall_score(all_labels, all_preds, average='micro')\n",
    "#         val_precision = precision_score(all_labels, all_preds, average='micro')\n",
    "\n",
    "#         print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}, F1-Score: {val_f1:.4f}, precision_score: {val_precision:.4f},Recall: {val_recall:.4f}\")\n",
    "#         print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726f52c-ebc7-4270-a54f-dc4f9aaf263f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4b35170-14be-4fd1-9496-fe440a0d91e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../clients_data/clients_trained_model/pre_trained_model.pth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = f\"../clients_data/clients_trained_model/pre_trained_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c85b07c-fb1f-49ac-ac84-71d9aebe5368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bd578f-a4a4-42e4-ae0d-273c4f4f14fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
