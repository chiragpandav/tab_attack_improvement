{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2774084-99a0-4a32-80c2-b40c84730925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import to_numeric\n",
    "from datasets.base_dataset import BaseDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "720d1905-e1e2-493c-9204-a5f7d790fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ADULT(BaseDataset):\n",
    "\n",
    "    def __init__(self, name='ADULT', single_bit_binary=False, device='cpu', random_state=42,name_state=0):\n",
    "        super(ADULT, self).__init__(name=name, device=device, random_state=random_state)\n",
    "\n",
    "        self.features = {\n",
    "            'age': None,\n",
    "            'workclass': ['Private', 'Self-emp-not-inc', 'Self-emp-inc', 'Federal-gov', 'Local-gov', 'State-gov',\n",
    "                          'Without-pay', 'Never-worked'],\n",
    "            'fnlwgt': None,\n",
    "            'education': ['Bachelors', 'Some-college', '11th', 'HS-grad', 'Prof-school', 'Assoc-acdm', 'Assoc-voc',\n",
    "                          '9th', '7th-8th', '12th', 'Masters',\n",
    "                          '1st-4th', '10th', 'Doctorate', '5th-6th', 'Preschool'],\n",
    "            'education-num': None,\n",
    "            'marital-status': ['Married-civ-spouse', 'Divorced', 'Never-married', 'Separated', 'Widowed',\n",
    "                               'Married-spouse-absent', 'Married-AF-spouse'],\n",
    "            'occupation': ['Tech-support', 'Craft-repair', 'Other-service', 'Sales', 'Exec-managerial',\n",
    "                           'Prof-specialty', 'Handlers-cleaners',\n",
    "                           'Machine-op-inspct', 'Adm-clerical', 'Farming-fishing', 'Transport-moving',\n",
    "                           'Priv-house-serv', 'Protective-serv', 'Armed-Forces'],\n",
    "            'relationship': ['Wife', 'Own-child', 'Husband', 'Not-in-family', 'Other-relative', 'Unmarried'],\n",
    "            'race': ['White', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other', 'Black'],\n",
    "            'sex': ['Female', 'Male'],\n",
    "            'capital-gain': None,\n",
    "            'capital-loss': None,\n",
    "            'hours-per-week': None,\n",
    "            'native-country': ['United-States', 'Cambodia', 'England', 'Puerto-Rico', 'Canada', 'Germany',\n",
    "                               'Outlying-US(Guam-USVI-etc)', 'India', 'Japan', 'Greece',\n",
    "                               'South', 'China', 'Cuba', 'Iran', 'Honduras', 'Philippines', 'Italy', 'Poland',\n",
    "                               'Jamaica', 'Vietnam', 'Mexico', 'Portugal', 'Ireland',\n",
    "                               'France', 'Dominican-Republic', 'Laos', 'Ecuador', 'Taiwan', 'Haiti', 'Columbia',\n",
    "                               'Hungary', 'Guatemala', 'Nicaragua', 'Scotland',\n",
    "                               'Thailand', 'Yugoslavia', 'El-Salvador', 'Trinadad&Tobago', 'Peru', 'Hong',\n",
    "                               'Holand-Netherlands'],\n",
    "            'income': ['>50K', '<=50K']\n",
    "        }\n",
    "\n",
    "        self.single_bit_binary = single_bit_binary\n",
    "        self.label = 'income'\n",
    "\n",
    "        self.train_features = {key: self.features[key] for key in self.features.keys() if key != self.label}\n",
    "\n",
    "        if name_state in [\"WM\",\"WW\",\"BM\",\"BW\"]:\n",
    "            train_data_df = pd.read_csv(f'../clients_data/raw_data/{name_state}.data', delimiter=',', names=list(self.features.keys()), engine='python')\n",
    "            test_data_df = pd.read_csv(f'../clients_data/raw_data/client_adult.test', delimiter=',', names=list(self.features.keys()), skiprows=1, engine='python')\n",
    "        elif name_state in [\"male\",\"female\",\"white\",\"black\"]:\n",
    "            train_data_df = pd.read_csv(f'../clients_data/raw_data/{name_state}.data', delimiter=',', names=list(self.features.keys()), engine='python')\n",
    "            test_data_df = pd.read_csv(f'../clients_data/raw_data/client_adult.test', delimiter=',', names=list(self.features.keys()), skiprows=1, engine='python')\n",
    "        elif name_state in [\"client_adult\"]:\n",
    "            #do not change this.. this is for creating test split of 10k\n",
    "            train_data_df = pd.read_csv(f'../clients_data/raw_data/{name_state}.test', delimiter=',', names=list(self.features.keys()), engine='python')\n",
    "            test_data_df = pd.read_csv(f'../clients_data/raw_data/client_adult.test', delimiter=',', names=list(self.features.keys()), skiprows=1, engine='python')\n",
    "        elif name_state in [\"data_pre_trained_model\"]:\n",
    "            \n",
    "            train_data_df = pd.read_csv(f'../clients_data/raw_data/client_{name_state}.data', delimiter=',', names=list(self.features.keys()), engine='python')\n",
    "            test_data_df = pd.read_csv(f'../clients_data/raw_data/client_adult.test', delimiter=',', names=list(self.features.keys()), skiprows=1, engine='python')\n",
    "        else:\n",
    "            train_data_df = pd.read_csv(f'../clients_data/raw_data/client_{name_state}.data', delimiter=',', names=list(self.features.keys()), engine='python')        \n",
    "            test_data_df = pd.read_csv(f'../clients_data/raw_data/client_{name_state}.test', delimiter=',', names=list(self.features.keys()), skiprows=1, engine='python')\n",
    "        \n",
    "        print(f\"training sample:: {name_state}.data and len is {len(train_data_df)}\")\n",
    "        print(f\"testing sample:: {name_state}.test and len is {len(test_data_df)}\")\n",
    "\n",
    "        # train_data_df = pd.read_csv('datasets/ADULT/adult.data', delimiter=', ', names=list(self.features.keys()), engine='python')\n",
    "        # test_data_df = pd.read_csv('datasets/ADULT/adult.test', delimiter=', ', names=list(self.features.keys()), skiprows=1, engine='python')\n",
    "\n",
    "        train_data = train_data_df.to_numpy()\n",
    "        test_data = test_data_df.to_numpy()\n",
    "\n",
    "        # drop missing values\n",
    "        # note that the category never worked always comes with a missing value for the occupation field, hence this\n",
    "        # step effectively removes the never worked category from the dataset\n",
    "        \n",
    "        train_rows_to_keep = [not ('?' in row) for row in train_data]\n",
    "        test_rows_to_keep = [not ('?' in row) for row in test_data]\n",
    "        train_data = train_data[train_rows_to_keep]\n",
    "        test_data = test_data[test_rows_to_keep]\n",
    "\n",
    "        # remove the annoying dot from the test labels\n",
    "        # for row in test_data:\n",
    "        #     row[-1] = row[-1][:-1]\n",
    "\n",
    "        # convert to numeric features\n",
    "        train_data_num = to_numeric(train_data, self.features, label=self.label, single_bit_binary=self.single_bit_binary)\n",
    "        test_data_num = to_numeric(test_data, self.features, label=self.label, single_bit_binary=self.single_bit_binary)\n",
    "\n",
    "        # split features and labels\n",
    "        Xtrain, Xtest = train_data_num[:, :-1].astype(np.float32), test_data_num[:, :-1].astype(np.float32)\n",
    "        ytrain, ytest = train_data_num[:, -1].astype(np.float32), test_data_num[:, -1].astype(np.float32)\n",
    "        self.num_features = Xtrain.shape[1]\n",
    "\n",
    "        print(np.unique(ytrain))\n",
    "        print(np.unique(ytest))\n",
    "\n",
    "        # transfer to torch\n",
    "        self.Xtrain, self.Xtest = torch.tensor(Xtrain).to(self.device), torch.tensor(Xtest).to(self.device)\n",
    "        self.ytrain, self.ytest = torch.tensor(ytrain, dtype=torch.long).to(self.device), torch.tensor(ytest, dtype=torch.long).to(self.device)\n",
    "\n",
    "        # set to train mode as base\n",
    "        self.train()\n",
    "\n",
    "        # calculate the standardization statistics\n",
    "        self._calculate_mean_std()\n",
    "\n",
    "        # calculate the histograms and feature bounds\n",
    "        self._calculate_categorical_feature_distributions_and_continuous_bounds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e55ca0-d483-432c-ba9f-a4b6377a32bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1030559c-81d6-493c-956f-ec07398f7f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a3c77a4-9461-4797-b08c-6ee61f308175",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training sample:: 0.data and len is 2000\n",
      "testing sample:: 0.test and len is 999\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "training sample:: 1.data and len is 2000\n",
      "testing sample:: 1.test and len is 999\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "training sample:: 2.data and len is 2000\n",
      "testing sample:: 2.test and len is 999\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "training sample:: 3.data and len is 2000\n",
      "testing sample:: 3.test and len is 999\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "training sample:: 4.data and len is 2000\n",
      "testing sample:: 4.test and len is 999\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "training sample:: 5.data and len is 2000\n",
      "testing sample:: 5.test and len is 999\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "training sample:: 6.data and len is 2000\n",
      "testing sample:: 6.test and len is 999\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "training sample:: 7.data and len is 2000\n",
      "testing sample:: 7.test and len is 999\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "training sample:: 8.data and len is 2000\n",
      "testing sample:: 8.test and len is 998\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "training sample:: 9.data and len is 2000\n",
      "testing sample:: 9.test and len is 998\n",
      "[0. 1.]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "state_codes = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "for state_code in state_codes:\n",
    "    state_name=state_code\n",
    "    adult_dataset = ADULT(name_state=state_name)\n",
    "    adult_dataset.standardize()\n",
    "    dataset = TensorDataset(adult_dataset.Xtrain, adult_dataset.ytrain)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "\n",
    "    with open(f'../clients_data/processed_data/{state_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(dataloader, f)\n",
    "        \n",
    "    dataset = TensorDataset(adult_dataset.Xtest, adult_dataset.ytest)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "    \n",
    "    with open(f'../clients_data/processed_data/{state_name}_test.pkl', 'wb') as f:\n",
    "        pickle.dump(dataloader, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1467f424-97c5-4f8c-9730-9f7e162baf57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a0241-35d7-42ff-bf1c-4e6cfc6f2e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c9a214-20b3-4473-ac1e-e40a6e5ced53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76e9c9c0-69bc-4192-ab7c-bc3302c3631e",
   "metadata": {},
   "source": [
    "# 10K traning processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09e4dca8-7d23-44df-8882-3937530d6ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training sample:: data_pre_trained_model.data and len is 2616\n",
      "testing sample:: data_pre_trained_model.test and len is 9999\n",
      "[0. 1.]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "state_name=\"data_pre_trained_model\"\n",
    "adult_dataset = ADULT(name_state=state_name)\n",
    "adult_dataset.standardize()\n",
    "dataset = TensorDataset(adult_dataset.Xtrain, adult_dataset.ytrain)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True) \n",
    "with open(f'../clients_data/processed_data/{state_name}.pkl', 'wb') as f:\n",
    "    pickle.dump(dataloader, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c51c02c-28f2-4250-878b-c4dd61cb615d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18ec24fc-5496-4a44-86e7-58b244f1f57c",
   "metadata": {},
   "source": [
    "# testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5771c4bb-2da8-4eab-9f21-9c4d931a594f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training sample:: client_adult.data and len is 10000\n",
      "testing sample:: client_adult.test and len is 9999\n",
      "[0. 1.]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "state_name=\"client_adult\"\n",
    "adult_dataset = ADULT(name_state=state_name)\n",
    "adult_dataset.standardize()\n",
    "dataset = TensorDataset(adult_dataset.Xtrain, adult_dataset.ytrain)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True) \n",
    "with open(f'../clients_data/processed_data/{state_name}.pkl', 'wb') as f:\n",
    "    pickle.dump(dataloader, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b519fe-d232-47fe-8975-b69838be225d",
   "metadata": {},
   "source": [
    "# group processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfaa3848-8e0c-4f07-9c35-7fd31248a35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training sample:: male.data and len is 6750\n",
      "testing sample:: male.test and len is 9999\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "training sample:: female.data and len is 3250\n",
      "testing sample:: female.test and len is 9999\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "training sample:: white.data and len is 8603\n",
      "testing sample:: white.test and len is 9999\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "training sample:: black.data and len is 935\n",
      "testing sample:: black.test and len is 9999\n",
      "[0. 1.]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "#============================ For testing =============================\n",
    "state_codes=[\"male\",\"female\",\"white\",\"black\"]\n",
    "\n",
    "for state_code in state_codes:\n",
    "    state_name=state_code\n",
    "    adult_dataset = ADULT(name_state=state_name)\n",
    "    adult_dataset.standardize()\n",
    "    dataset = TensorDataset(adult_dataset.Xtrain, adult_dataset.ytrain)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "\n",
    "    with open(f'../clients_data/client_subG_processed/{state_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(dataloader, f)\n",
    "        \n",
    "    dataset = TensorDataset(adult_dataset.Xtest, adult_dataset.ytest)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "    \n",
    "    with open(f'../clients_data/client_subG_processed/{state_name}_test.pkl', 'wb') as f:\n",
    "        pickle.dump(dataloader, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f39f5f2-507d-40f2-972f-b905d5e2d543",
   "metadata": {},
   "source": [
    "# Subgroup processed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cab72a-07d1-4eed-896d-2b49d3a4d3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99bf22a4-b18b-4e00-ad40-a6cb64cd4f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training sample:: WM.data and len is 5975\n",
      "testing sample:: WM.test and len is 9999\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "training sample:: WW.data and len is 2628\n",
      "testing sample:: WW.test and len is 9999\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "training sample:: BM.data and len is 474\n",
      "testing sample:: BM.test and len is 9999\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "training sample:: BW.data and len is 461\n",
      "testing sample:: BW.test and len is 9999\n",
      "[0. 1.]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "state_codes=[\"WM\",\"WW\",\"BM\",\"BW\"]\n",
    "\n",
    "for state_code in state_codes:\n",
    "    state_name=state_code\n",
    "    adult_dataset = ADULT(name_state=state_name)\n",
    "    adult_dataset.standardize()\n",
    "    dataset = TensorDataset(adult_dataset.Xtrain, adult_dataset.ytrain)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "\n",
    "    with open(f'../clients_data/client_subG_processed/{state_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(dataloader, f)\n",
    "        \n",
    "    dataset = TensorDataset(adult_dataset.Xtest, adult_dataset.ytest)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "    \n",
    "    with open(f'../clients_data/client_subG_processed/{state_name}_test.pkl', 'wb') as f:\n",
    "        pickle.dump(dataloader, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b230d1-255f-4463-be3a-4bf2a5168a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39bc124-d5e3-47ae-838a-750630853dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c77a3d7-7110-484c-9fc9-10726a419497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ef1f35-af17-45be-b1ea-ff7a81d8d0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bb957c-e476-4856-9de3-2cd085d68ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f6a886-f9ce-4f6f-ae09-9ad5c51fb45b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65797847-0f0c-46a5-be6d-ba22290684ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1914d73e-5be7-4fff-b8d5-c99228e9b692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703904c-df3b-447d-960a-b0d4d4f99228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae8472-7d82-4868-853e-bc76d0d535d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f48d6e2-13d5-4df1-bc7c-8f6712be86a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
